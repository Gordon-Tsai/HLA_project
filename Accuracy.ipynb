{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy 2 out of total number of accessions instead of  just true generalaccuracy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWx6FncHCSD2"
      },
      "source": [
        "def inputs(number_of_tests):\n",
        "  tool_names = list()\n",
        "  tool_locations = list()\n",
        "  name_and_dataframe_dict = dict()\n",
        "  accession, a, a1, b, b1, c, c1, full, dataset_number = list(), list(), list(), list(), list(), list(), list(), list(), list()\n",
        "  for i in range(number_of_tests):\n",
        "    tool_name = input(f\"What is the name of tool #{i+1} that you would like to check? \").lower()\n",
        "    tool_names.append(tool_name)\n",
        "    tool_location = input(f\"What is the location of the tool {tool_name} in goodle drive something like /content/gdrive/MyDrive/test/OPTITYPE/optitype_d1.csv  \")\n",
        "    make_sure = input(f\"are you sure that {tool_location} is the location of {tool_name} on your google drive? yes or no \").lower()\n",
        "    tool_locations.append(tool_location)\n",
        "  for h in range(len(tool_names)):\n",
        "    df = pd.read_csv(tool_locations[h])\n",
        "    df_len = len(df)\n",
        "    df_column_names = df.columns\n",
        "    name_and_dataframe_dict[tool_names[h]] = df\n",
        "  return name_and_dataframe_dict\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXBBUdNOHPSF"
      },
      "source": [
        "#initialize dictionary w all gs accession numbers\n",
        "#keys are accession numbers\n",
        "#initialize all values FALSE (do not exist in results)\n",
        "\n",
        "def create_gold_standard():\n",
        "  gold_standard_accessions = dict()\n",
        "  len1 = len(gold_standard_dataset1)\n",
        "  for i in range(len1):\n",
        "    gold_standard_accessions[gold_standard_dataset1[\"Run\"][i]]=False\n",
        "  print(gold_standard_accessions)\n",
        "  return gold_standard_accessions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGqdmOpNHV9y"
      },
      "source": [
        "def weeding_list_of_accessions(gold_standard_accessions,dataset1):\n",
        "  count = 0\n",
        "  dataset1_column_names = dataset1.columns\n",
        "  len2 = dataset1.shape\n",
        "  print(len2)\n",
        "  for key, value in gold_standard_accessions.items():\n",
        "    for i in range(len2[0]):\n",
        "      if key in dataset1[dataset1_column_names[0]][i]:\n",
        "        gold_standard_accessions[key] = True\n",
        "        count = count + 1\n",
        "  print(gold_standard_accessions, print(dataset1[dataset1_column_names[0]][0]))\n",
        "  print(count)\n",
        "  return gold_standard_accessions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djbbh10UuXdY"
      },
      "source": [
        "def false_values(gold_standard_accessions, dataset_number, tool_name):\n",
        "  falses = list()\n",
        "  for key, value in gold_standard_accessions.items():\n",
        "    if value == False:\n",
        "      falses.append(key)\n",
        "  falses.append(dataset_number)\n",
        "  falses.append(tool_name)\n",
        "  textfile = open(\"/content/gdrive/MyDrive/test/missing.txt\", \"a\")\n",
        "  for element in falses:\n",
        "    textfile.write(element + \" \")\n",
        "  textfile.write('\\n')\n",
        "  textfile.close()\n",
        "  return falses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pr3ynH_wDPoa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "a71b729f-18a8-432d-e3f3-380c9c75df11"
      },
      "source": [
        "def finding_accuracy(gold_standard_accessions, dataset1):\n",
        "  two_digit_res = 0\n",
        "  four_digit_res = 0\n",
        "  total_count = 0\n",
        "  gold_standard_dataset1_column_remove_access = gold_standard_dataset1_column_names[1:]\n",
        "  dataset1_column_names = dataset1.columns\n",
        "  dataset1_column_remove_access = dataset1_column_names[1:]\n",
        "  import numpy as np\n",
        "\n",
        "  for key, value in gold_standard_accessions.items():\n",
        "    if value == True:\n",
        "      for i in range((len(gold_standard_dataset1_column_names))-1):\n",
        "        total_count = total_count + 1\n",
        "        #https://stackoverflow.com/questions/53255796/how-to-get-a-single-value-as-a-string-from-pandas-data-frame\n",
        "        dataset1_string =  dataset1.loc[dataset1[dataset1_column_names[0]] == key, [dataset1_column_names[i+1]]].values[0]\n",
        "        gold_standard_dataset1_string =  gold_standard_dataset1.loc[gold_standard_dataset1[gold_standard_dataset1_column_names[0]] == key, [gold_standard_dataset1_column_names[i+1]]].values[0]\n",
        "        dataset1_string = str(dataset1_string)\n",
        "        #print(dataset1_string)\n",
        "        gold_standard_dataset1_string = str(gold_standard_dataset1_string)\n",
        "        #print(gold_standard_dataset1_string)\n",
        "        # 2 to 3 is the letter 4 to 6 are the first two digits and 7 to 9 are the last two digits so while have othave symbol between A and whatever and the collen, it does not have to be an astixor colon\n",
        "        if dataset1_string[2:3] == gold_standard_dataset1_string[2:3] and dataset1_string[4:6] == gold_standard_dataset1_string[4:6]:\n",
        "          two_digit_res = two_digit_res + 1\n",
        "        if dataset1_string[2:3] == gold_standard_dataset1_string[2:3] and dataset1_string[4:6] == gold_standard_dataset1_string[4:6] and dataset1_string[7:9] == gold_standard_dataset1_string[7:9]:\n",
        "          four_digit_res = four_digit_res + 1\n",
        "  final_two_digit_res_accuracy = two_digit_res/(len(gold_standard_dataset1)*6)\n",
        "  final_four_digit_res_accuracy = four_digit_res/(len(gold_standard_dataset1)*6)\n",
        "  print(two_digit_res, four_digit_res, total_count, final_two_digit_res_accuracy, final_four_digit_res_accuracy)\n",
        "  return final_two_digit_res_accuracy, final_four_digit_res_accuracy\n",
        "'''\n",
        "#THE SUPERIOR CODE BY DOTTIE, please make mine more efficient if possible \n",
        "count = 0\n",
        "totalcount=0\n",
        "import numpy as np\n",
        "numpyarr = []\n",
        "\n",
        "for key, value in gold_standard_accessions.items():\n",
        "  if value == True:\n",
        "    try:\n",
        "      sample = dataset1.loc[dataset1['Run'] == key]\n",
        "      gs = gold_standard_dataset1.loc[gold_standard_dataset1['Run'] == key]\n",
        "\n",
        "      sample = sample.reset_index(drop=True)\n",
        "      gs = gs.reset_index(drop=True)\n",
        "\n",
        "      a=(sample[0:]== gs[0:])\n",
        "      numpyarr.append(a.values)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "\n",
        "print(numpyarr)\n",
        "for i in numpyarr:\n",
        "  for j in i:\n",
        "    count = count-1\n",
        "    totalcount = totalcount-1  #subtract to get rid of the first element, which is always true (accession numbers are equal)\n",
        "    for k in j:\n",
        "      totalcount = totalcount+1\n",
        "      if k.all() == True:\n",
        "        count = count+1\n",
        "\n",
        "\n",
        "print(count)\n",
        "print(totalcount)\n",
        "'''\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n#THE SUPERIOR CODE BY DOTTIE, please make mine more efficient if possible \\ncount = 0\\ntotalcount=0\\nimport numpy as np\\nnumpyarr = []\\n\\nfor key, value in gold_standard_accessions.items():\\n  if value == True:\\n    try:\\n      sample = dataset1.loc[dataset1['Run'] == key]\\n      gs = gold_standard_dataset1.loc[gold_standard_dataset1['Run'] == key]\\n\\n      sample = sample.reset_index(drop=True)\\n      gs = gs.reset_index(drop=True)\\n\\n      a=(sample[0:]== gs[0:])\\n      numpyarr.append(a.values)\\n    except:\\n      pass\\n\\n\\nprint(numpyarr)\\nfor i in numpyarr:\\n  for j in i:\\n    count = count-1\\n    totalcount = totalcount-1  #subtract to get rid of the first element, which is always true (accession numbers are equal)\\n    for k in j:\\n      totalcount = totalcount+1\\n      if k.all() == True:\\n        count = count+1\\n\\n\\nprint(count)\\nprint(totalcount)\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Fgl3vqWKmT8"
      },
      "source": [
        "def finding_accuracy2(gold_standard_accessions, dataset1):\n",
        "  two_digit_res = 0\n",
        "  four_digit_res = 0\n",
        "  two_digit_bool = False\n",
        "  four_digit_bool = False\n",
        "  total_count = 0\n",
        "  gold_standard_dataset1_column_remove_access = gold_standard_dataset1_column_names[1:]\n",
        "  dataset1_column_names = dataset1.columns\n",
        "  dataset1_column_remove_access = dataset1_column_names[1:]\n",
        "  import numpy as np\n",
        "\n",
        "  for key, value in gold_standard_accessions.items():\n",
        "    if value == True:\n",
        "      for i in range((len(dataset1_column_names))-1):\n",
        "        total_count = total_count + 1\n",
        "        #https://stackoverflow.com/questions/53255796/how-to-get-a-single-value-as-a-string-from-pandas-data-frame\n",
        "        dataset1_string =  dataset1.loc[dataset1[dataset1_column_names[0]] == key, [dataset1_column_names[i+1]]].values[0]\n",
        "        gold_standard_dataset1_string =  gold_standard_dataset1.loc[gold_standard_dataset1[gold_standard_dataset1_column_names[0]] == key, [gold_standard_dataset1_column_names[i+1]]].values[0]\n",
        "        dataset1_string = str(dataset1_string)\n",
        "        dataset1_string = dataset1_string.strip(\"[]''\")\n",
        "        #print(dataset1_string)\n",
        "        gold_standard_dataset1_string = str(gold_standard_dataset1_string)\n",
        "        gold_standard_dataset1_string = gold_standard_dataset1_string.strip(\"[]''\")\n",
        "        gold_standard_dataset1_length = len(gold_standard_dataset1_string)\n",
        "        if(gold_standard_dataset1_string.find('/')):\n",
        "          gold_standard_dataset1_list_of_types = gold_standard_dataset1_string.split('/')\n",
        "          for hlatype in gold_standard_dataset1_list_of_types:\n",
        "            if len(hlatype) == 4:\n",
        "              hlatype = '0'+hlatype\n",
        "            if hlatype[:2] == dataset1_string[2:4]:\n",
        "              two_digit_bool = True\n",
        "            if hlatype[:2] == dataset1_string[2:4] and hlatype[3:5] == dataset1_string[5:7]:\n",
        "              four_digit_bool = True\n",
        "        #print(gold_standard_dataset1_string, gold_standard_dataset1_length)\n",
        "        #print(gold_standard_dataset1_list_of_types)\n",
        "        #delimiter / find / make list of strings add for loop to go through strings in list and check if  statments add bool and if true/ found the same add 1 to count\n",
        "        # 2 to 3 is the letter 4 to 6 are the first two digits and 7 to 9 are the last two digits so while have othave symbol between A and whatever and the collen, it does not have to be an astixor colon\n",
        "        if len(gold_standard_dataset1_string) == 4:\n",
        "          gold_standard_dataset1_string = '0'+ gold_standard_dataset1_string\n",
        "        if (dataset1_string[2:4] == gold_standard_dataset1_string[:2]) or two_digit_bool == True:\n",
        "          two_digit_res = two_digit_res + 1\n",
        "          #print(gold_standard_dataset1_string)\n",
        "        if (dataset1_string[2:4] == gold_standard_dataset1_string[:2] and dataset1_string[5:7] == gold_standard_dataset1_string[3:5]) or four_digit_bool == True:\n",
        "          four_digit_res = four_digit_res + 1\n",
        "        two_digit_bool = False\n",
        "        four_digit_bool = False\n",
        "  final_two_digit_res_accuracy = two_digit_res/(len(gold_standard_dataset1)*6)\n",
        "  final_four_digit_res_accuracy = four_digit_res/(len(gold_standard_dataset1)*6)\n",
        "  print(two_digit_res, four_digit_res, total_count, final_two_digit_res_accuracy, final_four_digit_res_accuracy)\n",
        "  return final_two_digit_res_accuracy, final_four_digit_res_accuracy\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DbsQ1KPOwbd"
      },
      "source": [
        "def finding_accuracy3(gold_standard_accessions, dataset1):\n",
        "\n",
        "  two_digit_res = 0\n",
        "  four_digit_res = 0\n",
        "  #two_digit_bool = False\n",
        "  #four_digit_bool = False\n",
        "  total_count = 0\n",
        "  DRB1_2_digit_count = 0\n",
        "  DRB1_4_digit_count = 0\n",
        "  DRB2_2_digit_count = 0\n",
        "  DRB2_4_digit_count = 0\n",
        "  dataset1_column_names = dataset1.columns\n",
        "\n",
        "  gold_standard_dataset1[['DRB1','DRB2']] = gold_standard_dataset1.DRB1.str.split(\"/\",expand=True)\n",
        "  dataset1 = dataset1.drop_duplicates(subset=[dataset1_column_names[0]])\n",
        "\n",
        "  import numpy as np\n",
        "  for key, value in gold_standard_accessions.items():\n",
        "    if value == True:\n",
        "      total_count = total_count + 2\n",
        "\n",
        "      inde = str(gold_standard_dataset1.index[gold_standard_dataset1[gold_standard_dataset1_column_names[0]] == key].tolist())\n",
        "      inde = inde.strip(\"[]''\")\n",
        "      inde = int(inde)\n",
        "      expected_DRB1 = str(gold_standard_dataset1['DRB1'][inde])\n",
        "\n",
        "      inde = str(dataset1.index[dataset1[dataset1_column_names[0]] == key].tolist())\n",
        "      inde = inde.strip(\"[]''\")\n",
        "      inde = int(inde)\n",
        "      predicted_DRB1 = str(dataset1[dataset1_column_names[1]][inde])\n",
        "\n",
        "      if predicted_DRB1[5:7] == expected_DRB1[1:3]:\n",
        "        DRB1_2_digit_count = DRB1_2_digit_count + 1\n",
        "      if predicted_DRB1[5:10] == expected_DRB1[1:6]:\n",
        "        DRB1_4_digit_count = DRB1_4_digit_count + 1\n",
        "\n",
        "\n",
        "      inde = str(gold_standard_dataset1.index[gold_standard_dataset1[gold_standard_dataset1_column_names[0]] == key].tolist())\n",
        "      inde = inde.strip(\"[]''\")\n",
        "      inde = int(inde)\n",
        "      expected_DRB2 = gold_standard_dataset1['DRB2'][inde]\n",
        "\n",
        "      inde = str(dataset1.index[dataset1[dataset1_column_names[0]] == key].tolist())\n",
        "      inde = inde.strip(\"[]''\")\n",
        "      inde = int(inde)\n",
        "      predicted_DRB2 = dataset1[dataset1_column_names[2]][inde]\n",
        "\n",
        "      if predicted_DRB2[5:7] == expected_DRB2[1:3]:\n",
        "        DRB2_2_digit_count = DRB2_2_digit_count + 1\n",
        "      if predicted_DRB2[5:10] == expected_DRB2[1:6]:\n",
        "        DRB2_4_digit_count = DRB2_4_digit_count + 1\n",
        "\n",
        "\n",
        "  two_digit_res = (DRB1_2_digit_count + DRB2_2_digit_count)/total_count\n",
        "  four_digit_res = (DRB1_4_digit_count + DRB2_4_digit_count)/total_count\n",
        "  print(gold_standard_dataset1['DRB2'])\n",
        "  return two_digit_res, four_digit_res \n",
        "\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nGH5Sq8CL6q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "7d49968f-977d-4d5e-eb85-184f802065fa"
      },
      "source": [
        "# ask user for stuff\n",
        "import pandas as pd\n",
        "import csv\n",
        "import os\n",
        "import json\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "loc_gs = '/content/gdrive/MyDrive/test/datasets'\n",
        "'''\n",
        "gold_standard_dataset1 = pd.read_csv(loc_gs+'/1_gs.csv')\n",
        "gold_standard_dataset1_column_names = gold_standard_dataset1.columns\n",
        "gold_standard_dataset2 = pd.read_csv(loc_gs+'/2_gs.csv')\n",
        "gold_standard_dataset2_column_names = gold_standard_dataset2.columns\n",
        "'''\n",
        "\n",
        "dictionary = dict()\n",
        "accuracy = list()\n",
        "what_dataset = input('What dataset would you like to check the accuracy for? 1, 2, 3, 4, 5, or 6 (pleaase oly imput the integer)')\n",
        "number_of_tests = int(input(\"How many tools would you like to check the accuracy of in regard to ? \"))\n",
        "final_dict = dict()\n",
        "d = inputs(number_of_tests)\n",
        "print(type(what_dataset))\n",
        "for key, value in d.items():\n",
        "  if what_dataset == '1':\n",
        "    gold_standard_dataset1 = pd.read_csv(loc_gs+'/1_gs.csv')\n",
        "    gold_standard_dataset1_column_names = gold_standard_dataset1.columns\n",
        "\n",
        "    gold_standard_accessions = create_gold_standard()\n",
        "    weeding_accessions = weeding_list_of_accessions(gold_standard_accessions, value)\n",
        "    accuracy = list(finding_accuracy(weeding_accessions, value))\n",
        "\n",
        "    false_values(weeding_accessions, what_dataset, key)\n",
        "\n",
        "    accuracy.append(what_dataset)\n",
        "    dictionary[key] = accuracy\n",
        "  elif what_dataset == '2':\n",
        "    gold_standard_dataset1 = pd.read_csv(loc_gs+'/2_gs.csv')\n",
        "    gold_standard_dataset1_column_names = gold_standard_dataset1.columns\n",
        "\n",
        "    gold_standard_accessions = create_gold_standard()\n",
        "    weeding_accessions = weeding_list_of_accessions(gold_standard_accessions, value)\n",
        "    accuracy = list(finding_accuracy2(weeding_accessions, value))\n",
        "\n",
        "    false_values(weeding_accessions, what_dataset, key)\n",
        "\n",
        "    accuracy.append(what_dataset)\n",
        "    dictionary[key] = accuracy\n",
        "  elif what_dataset == '3':\n",
        "    print(\"HI**********************************************************************\")\n",
        "    gold_standard_dataset1 = pd.read_csv(loc_gs+'/3_gs.csv')\n",
        "    gold_standard_dataset1_column_names = gold_standard_dataset1.columns\n",
        "\n",
        "    gold_standard_accessions = create_gold_standard()\n",
        "    weeding_accessions = weeding_list_of_accessions(gold_standard_accessions, value)\n",
        "    accuracy = list(finding_accuracy2(weeding_accessions, value))\n",
        "\n",
        "    false_values(weeding_accessions, what_dataset, key)\n",
        "\n",
        "    accuracy.append(what_dataset)\n",
        "    dictionary[key] = accuracy\n",
        "    print(value)\n",
        "print(dictionary)\n",
        "  \n",
        "'''\n",
        "  accuracy(caller,d)\n",
        "  print()\n",
        "  '''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "What dataset would you like to check the accuracy for? 1, 2, 3, 4, 5, or 6 (pleaase oly imput the integer)1\n",
            "How many tools would you like to check the accuracy of in regard to ? 1\n",
            "What is the name of tool #1 that you would like to check? optitype\n",
            "What is the location of the tool optitype in goodle drive something like /content/gdrive/MyDrive/test/OPTITYPE/optitype_d1.csv  /content/gdrive/MyDrive/test/optitype.csv\n",
            "are you sure that /content/gdrive/MyDrive/test/optitype.csv is the location of optitype on your google drive? yes or no yes\n",
            "<class 'str'>\n",
            "{'ERR009159': False, 'ERR009168': False, 'ERR009154': False, 'ERR009147': False, 'ERR009133': False, 'ERR009146': False, 'ERR009167': False, 'ERR009097': False, 'ERR009124': False, 'ERR009122': False, 'ERR009140': False, 'ERR009096': False, 'ERR009109': False, 'ERR009142': False, 'ERR009135': False, 'ERR009166': False, 'ERR009149': False, 'ERR009119': False, 'ERR009103': False, 'ERR009141': False, 'ERR009108': False, 'ERR009121': False, 'ERR009139': False, 'ERR009155': False, 'ERR009123': False, 'ERR009163': False, 'ERR009157': False, 'ERR009113': False, 'ERR009117': False, 'ERR009129': False, 'ERR009115': False, 'ERR009136': False, 'ERR009144': False, 'ERR009107': False, 'ERR009118': False, 'ERR009164': False, 'ERR009137': False, 'ERR009132': False, 'ERR009130': False, 'ERR009106': False, 'ERR009156': False, 'ERR009152': False, 'ERR009104': False, 'ERR009114': False, 'ERR009134': False, 'ERR009151': False, 'ERR009099': False, 'ERR009111': False, 'ERR009145': False, 'ERR009105': False}\n",
            "(50, 91)\n",
            "ERR009096\n",
            "{'ERR009159': True, 'ERR009168': True, 'ERR009154': True, 'ERR009147': True, 'ERR009133': True, 'ERR009146': True, 'ERR009167': True, 'ERR009097': True, 'ERR009124': True, 'ERR009122': True, 'ERR009140': True, 'ERR009096': True, 'ERR009109': True, 'ERR009142': True, 'ERR009135': True, 'ERR009166': True, 'ERR009149': True, 'ERR009119': True, 'ERR009103': True, 'ERR009141': True, 'ERR009108': True, 'ERR009121': True, 'ERR009139': True, 'ERR009155': True, 'ERR009123': True, 'ERR009163': True, 'ERR009157': True, 'ERR009113': True, 'ERR009117': True, 'ERR009129': True, 'ERR009115': True, 'ERR009136': True, 'ERR009144': True, 'ERR009107': True, 'ERR009118': True, 'ERR009164': True, 'ERR009137': True, 'ERR009132': True, 'ERR009130': True, 'ERR009106': True, 'ERR009156': True, 'ERR009152': True, 'ERR009104': True, 'ERR009114': True, 'ERR009134': True, 'ERR009151': True, 'ERR009099': True, 'ERR009111': True, 'ERR009145': True, 'ERR009105': True} None\n",
            "50\n",
            "170 159 300 0.5666666666666667 0.53\n",
            "{'optitype': [0.5666666666666667, 0.53, '1']}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n  accuracy(caller,d)\\n  print()\\n  '"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqM6qEJUY-53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a433d39-83fe-433a-dbda-ce61a5b2a2dd"
      },
      "source": [
        "#save accuracy into csv and tool name and dataset number check if what is in file is in new dict if so delete what is in file and append what is in dicitonary \n",
        "import os\n",
        "tools, two_dig, four_dig, dataset = list(), list(), list(), list()\n",
        "for key, value in dictionary.items():\n",
        "  tools.append(key.title())\n",
        "  two_dig.append(dictionary[key][0])\n",
        "  four_dig.append(dictionary[key][1])\n",
        "  dataset.append(dictionary[key][2])\n",
        "df1 = pd.DataFrame({'tools':tools})\n",
        "df2 = pd.DataFrame({'two_digit_resolution_accuracy':two_dig})\n",
        "df3 = pd.DataFrame({'four_digit_resolution_accuracy':four_dig})\n",
        "df4 = pd.DataFrame({'dataset_number':dataset})\n",
        "first_csv = pd.concat([df1,df2,df3,df4], axis=1, join='inner')\n",
        "\n",
        "first_csv\n",
        "\n",
        "final_csv = pd.DataFrame()\n",
        "filename = '/content/gdrive/MyDrive/test/accuracy.csv'\n",
        "\n",
        "try:\n",
        "  with open(filename) as f:\n",
        "    file_contents = pd.read_csv(filename)\n",
        "    lenth = len(file_contents)\n",
        "    for i in range(lenth):\n",
        "      for j in range(len(first_csv)):\n",
        "        if file_contents['tools'][i] == first_csv['tools'][j] and int(file_contents['dataset_number'][i]) == int(first_csv['dataset_number'][j]):\n",
        "          file_contents.drop([i], inplace = True)\n",
        "    final_csv = final_csv.append(file_contents, ignore_index=True)\n",
        "    final_csv = final_csv.append(first_csv, ignore_index=True)\n",
        "    final_csv.drop(final_csv.columns[final_csv.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
        "    os.remove(filename)\n",
        "    final_csv.to_csv(filename)\n",
        "except FileNotFoundError:\n",
        "  first_csv.drop(first_csv.columns[first_csv.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
        "  first_csv.to_csv(filename)\n",
        "\n",
        "\n",
        "df = pd.read_csv(filename)\n",
        "df.drop(df.columns[df.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      tools  ...  dataset_number\n",
            "0   Seq2Hla  ...             1.0\n",
            "1   Rna2Hla  ...             1.0\n",
            "2  Optitype  ...             2.0\n",
            "3   Hlapers  ...             1.0\n",
            "4  Optitype  ...             1.0\n",
            "\n",
            "[5 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "md41gVFOZd8K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "outputId": "76a81e1a-18f5-4717-83e1-52fb99a4ec16"
      },
      "source": [
        "\n",
        "column_names = df.columns\n",
        "for i in range(len(df)):\n",
        "  print(type(df[column_names[-1]][i]))\n",
        "  if df[column_names[-1]][i] != int(what_dataset):\n",
        "    df.drop([i], inplace = True)\n",
        "\n",
        "\n",
        "plt = df.plot.bar(x='tools')\n",
        "\n",
        "fig_file = f\"/content/gdrive/MyDrive/test/dataset{what_dataset}_bar_plot.jpg\"\n",
        "#not working\n",
        "ax.figure.savefig(fig_file)\n",
        "\n",
        "\n",
        "'''\n",
        "#HELP!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "!pip install matplotlib==3.4.1\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "length = len(df)\n",
        "tool_names = list()\n",
        "two_digit = list()\n",
        "four_digit = list()\n",
        "for i in range(length):\n",
        "  if int(df['dataset_number'][i]) == int(what_dataset):\n",
        "    tool_names.append(df['tools'][i])\n",
        "    two_digit.append(df['two_digit_resolution_accuracy'][i])\n",
        "    four_digit.append(df['four_digit_resolution_accuracy'][i])\n",
        "x = np.arange(len(tool_names))\n",
        "width = 0.35  # the width of the bars\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "rects1 = ax.bar(x - width/2, two_digit, width, label='Two Digit Resolution_accuracy')\n",
        "rects2 = ax.bar(x + width/2, four_digit, width, label='Four Digit Resolution Accuracy')\n",
        "\n",
        "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_title(f'Tool Accuracy for 2-digit and 4-digit Resolution for Dataset {what_dataset}')\n",
        "ax.set_xticks(x, tool_names)\n",
        "ax.legend()\n",
        "\n",
        "# Label with label_type 'center' instead of the default 'edge'\n",
        "ax.bar_label(rects1, label_type='center')\n",
        "ax.bar_label(rects2, label_type='center')\n",
        "\n",
        "plt.show()\n",
        "'''\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.int64'>\n",
            "<class 'numpy.int64'>\n",
            "<class 'numpy.int64'>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 3",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-4c5e498153f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcolumn_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhat_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 3"
          ]
        }
      ]
    }
  ]
}